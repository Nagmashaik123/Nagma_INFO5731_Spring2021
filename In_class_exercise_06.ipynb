{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagmashaik123/Nagma_INFO5731_Spring2021/blob/main/In_class_exercise_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 3/2/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvR_O9D8sOUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02046595-0de1-4ef8-d608-e8808fe87f8c"
      },
      "source": [
        "!pip uninstall tensorflow -y\n",
        "!pip install  tensorflow==2.0"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.0.0:\n",
            "  Successfully uninstalled tensorflow-2.0.0\n",
            "Collecting tensorflow==2.0\n",
            "  Using cached https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (2.0.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.19.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (2.0.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0) (54.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.24.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.27.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.3.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2020.12.5)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.4.0)\n",
            "Installing collected packages: tensorflow\n",
            "Successfully installed tensorflow-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ1uvkuEpJLV",
        "outputId": "6f16e4e8-ad9c-4650-d5c4-5859e90d81b2"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be9AHDidqf0k"
      },
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "pageNumber = [0,10,20,30,40,50,60,70,80,90]\n",
        "name_List = [ ]\n",
        "List = [ ]\n",
        "\n",
        "for pgCount in pageNumber:\n",
        "  page = requests.get('https://citeseerx.ist.psu.edu/search;jsessionid=87FF6C66EA09F22314C131669600CF98?q=natural+language+processing&t=doc&sort=rlv&start='+ str (pgCount))\n",
        "  bfSoup = BeautifulSoup(page.content,'html.parser')\n",
        "  List.append(bfSoup.find_all('a',class_='remove doc_details'))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY6723ljq4il"
      },
      "source": [
        "for item in List:\n",
        "  for ele in range(len(item)):\n",
        "    name_List.append(item[ele].get_text())"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti1pH6f2rC-2",
        "outputId": "af44fcd3-998f-4f5d-a752-b627cbc2a3fa"
      },
      "source": [
        "name_List"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n                  Foundations of statistical natural language processing\\n',\n",
              " '\\n                  A Maximum Entropy approach to Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Linguistics and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural language processing (almost) from scratch \\n                  ',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\nNatural Language Processing/Robotics\\n                  ',\n",
              " '\\n                  Tutorial on Natural Language Processing\\n',\n",
              " '\\n                  Ambiguities in Natural Language Processing\\n',\n",
              " '\\n                  Statistical Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing for Information Retrieval\\n                  ',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural language processing of lyrics\\n                  ',\n",
              " '\\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  ',\n",
              " '\\n                  Connectionist Natural Language Processing\\n',\n",
              " '\\n                  Chaos and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing:\\n                  ',\n",
              " '\\nNatural language processing: an introduction\\n                  ',\n",
              " '\\n                  Overview of Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Evaluating Natural Language Processing Systems\\n                  ',\n",
              " '\\n                  Analysis and Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing using NLTK and\\n                  ',\n",
              " '\\nNatural Language Processing Complexity and Parallelism\\n                  ',\n",
              " '\\n                  Large Lexicons For Natural Language Processing:\\n                  ',\n",
              " '\\nNatural Language Processing: Structure and Complexity\\n                  ',\n",
              " '\\n                  Deep Learning for Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing of Textual Requirements\\n                  ',\n",
              " '\\nNatural Language Processing and Information Retrieval\\n                  ',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\n                  Ants for Natural Language Processing\\n',\n",
              " '\\n                  ontologies, natural language processing\\n',\n",
              " '\\nNatural language processing\\n',\n",
              " '\\n                  Retrieval or Natural Language Processing\\n',\n",
              " '\\n                  THESAURUSES FOR NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\nNatural Language Processing\\n',\n",
              " '\\nNatural Language Processing Section\\n                  ',\n",
              " '\\nNatural Language Processing for\\n                  ',\n",
              " '\\nNatural Language Processing Group\\n                  ',\n",
              " '\\n                  BIOMEDICAL NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\n                  learning in Natural Language Processing\\n',\n",
              " '\\n                  An Introduction to Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing 2\\n                  ',\n",
              " '\\n                  Integrating speech and natural-language processing\\n',\n",
              " '\\n                  Paradigm Merger in Natural Language Processing\\n',\n",
              " '\\n                  on Visual Tools for Natural Language Processing\\n',\n",
              " '\\n                  Description Logics for Natural Language Processing\\n',\n",
              " '\\n                  STRUCTURE LEARNING FOR NATURAL LANGUAGE PROCESSING\\n',\n",
              " '\\n                  Commercial applications of natural language processing\\n',\n",
              " '\\n                  2008. Networks and natural language processing\\n',\n",
              " '\\n                  Current Issues in Software Engineering for Natural Language Processing\\n',\n",
              " '\\n                  Kernelized Sorting for Natural Language Processing\\n',\n",
              " '\\n                  Distributional Approaches to Natural Language Processing\\n',\n",
              " '\\n                  Decomposable Modeling in Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing in Information Retrieval\\n                  ',\n",
              " '\\n                  Information Retrieval in Malayalam Using Natural Language Processing\\n',\n",
              " '\\n                  On Natural Language Processing and Plan Recognition\\n                  ',\n",
              " '\\n                  On Natural Language Processing and Plan Recognition\\n                  ',\n",
              " '\\nNatural Language Processing in Information Retrieval\\n                  ',\n",
              " '\\n                  Induction, Logic, and Natural Language Processing\\n',\n",
              " '\\n                  On Statistical Methods in Natural Language Processing\\n',\n",
              " '\\n                  Machine Learning and Natural Language Processing\\n',\n",
              " '\\n                  Machine Learning in Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing In Computer-Assisted Language Learning\\n                  ',\n",
              " '\\n                  SESSION 9: NATURAL LANGUAGE PROCESSINGS\\n',\n",
              " '\\nNatural Language Processing: A Survey\\n                  ',\n",
              " '\\n                   An Overview of Probabilistic Tree Transducers for Natural Language Processing\\n',\n",
              " '\\n                  Principles of Evaluation in Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing with ThoughtTreasure\\n                  ',\n",
              " '\\n                  A broad-coverage natural language processing system\\n                  ',\n",
              " '\\n                  Logic Programming for Natural Language Processing\\n',\n",
              " '\\n                  A unified architecture for natural language processing: Deep neural networks with multitask learning\\n                  ',\n",
              " '\\n                  Information Retrieval Using Robust Natural Language Processing\\n',\n",
              " '\\n                  An overview of empirical natural language processing\\n',\n",
              " '\\n                  Towards Context-adaptive Natural Language Processing Systems \\n                  ',\n",
              " '\\n                  Teaching Applied Natural Language Processing: Triumphs and Tribulations\\n                  ',\n",
              " '\\n                  On Memory Limitations In Natural Language Processing\\n',\n",
              " '\\nNatural Language Processing: An approach to Parsing and Semantic Analysis\\n                  ',\n",
              " '\\n                  A REVIEW ON THE PROGRESS OF NATURAL LANGUAGE PROCESSING IN INDIA\\n                  ',\n",
              " '\\n                  An Evaluation of LOLITA and Related Natural Language Processing Systems\\n                  ',\n",
              " '\\n                  Web-based models for natural language processing\\n',\n",
              " '\\n                  Computer-Assisted Language Learning And Natural Language Processing\\n',\n",
              " '\\n                  Learning schemata for natural language processing\\n',\n",
              " '\\n                  Software Infrastructure for Natural Language Processing\\n',\n",
              " '\\n                  1. CONFIDENCE ESTIMATION FOR NATURAL LANGUAGE PROCESSING APPLICATIONS\\n                  ',\n",
              " '\\n                  Lexical Issues in Natural Language Processing\\n',\n",
              " '\\n                  The Stanford CoreNLP Natural Language Processing Toolkit\\n                  ',\n",
              " '\\n                  Gaussian Processes for Natural Language Processing\\n',\n",
              " '\\n                  An Historical Overview of Natural Language Processing Systems That Learn\\n                  ',\n",
              " '\\n                  Upper Modeling: organizing knowledge for natural language processing\\n',\n",
              " '\\n                  Self-Organizing Maps In Natural Language Processing\\n',\n",
              " '\\n                  A Workbench for Developing Natural Language Processing Tools\\n                  ',\n",
              " '\\nNatural Language Processing and its Use in Education\\n                  ',\n",
              " '\\n                  Neural Network Computing and Natural Language Processing*\\n                  ',\n",
              " '\\n                  Text Statistics Tool Box For Natural Language Processing\\n',\n",
              " '\\n                  Using Frame Semantics in Natural Language Processing\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MgVmaPterKtl",
        "outputId": "2e0c63c2-4a24-4150-9f9e-8f4ff294d749"
      },
      "source": [
        "df = pd.DataFrame({'Titles':name_List})\n",
        "df\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                  Foundations of statistical natural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                  A Maximum Entropy approach to Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                  Linguistics and Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\\nNatural language processing (almost) from scratch \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>\\nNatural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>\\nNatural Language Processing/Robotics\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>\\n                  Tutorial on Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\\n                  Ambiguities in Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\\n                  Statistical Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\\nNatural Language Processing for Information Retrieval\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\\nNatural language processing of lyrics\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\\n                  Connectionist Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>\\n                  Chaos and Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>\\nNatural Language Processing:\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>\\nNatural language processing: an introduction\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>\\n                  Overview of Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>\\n                  Evaluating Natural Language Processing Systems\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>\\n                  Analysis and Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>\\nNatural Language Processing using NLTK and\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>\\nNatural Language Processing Complexity and Parallelism\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>\\n                  Large Lexicons For Natural Language Processing:\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>\\nNatural Language Processing: Structure and Complexity\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>\\n                  Deep Learning for Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>\\nNatural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>\\nNatural Language Processing of Textual Requirements\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>\\n                   An Overview of Probabilistic Tree Transducers for Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>\\n                  Principles of Evaluation in Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>\\nNatural Language Processing with ThoughtTreasure\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>\\n                  A broad-coverage natural language processing system\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>\\n                  Logic Programming for Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>\\n                  A unified architecture for natural language processing: Deep neural networks with multitask learning\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>\\n                  Information Retrieval Using Robust Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>\\n                  An overview of empirical natural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>\\n                  Towards Context-adaptive Natural Language Processing Systems \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>\\n                  Teaching Applied Natural Language Processing: Triumphs and Tribulations\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>\\n                  On Memory Limitations In Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>\\nNatural Language Processing: An approach to Parsing and Semantic Analysis\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>\\n                  A REVIEW ON THE PROGRESS OF NATURAL LANGUAGE PROCESSING IN INDIA\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>\\n                  An Evaluation of LOLITA and Related Natural Language Processing Systems\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>\\n                  Web-based models for natural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>\\n                  Computer-Assisted Language Learning And Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>\\n                  Learning schemata for natural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>\\n                  Software Infrastructure for Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>\\n                  1. CONFIDENCE ESTIMATION FOR NATURAL LANGUAGE PROCESSING APPLICATIONS\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>\\n                  Lexical Issues in Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>\\n                  The Stanford CoreNLP Natural Language Processing Toolkit\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>\\n                  Gaussian Processes for Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>\\n                  An Historical Overview of Natural Language Processing Systems That Learn\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>\\n                  Upper Modeling: organizing knowledge for natural language processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>\\n                  Self-Organizing Maps In Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>\\n                  A Workbench for Developing Natural Language Processing Tools\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>\\nNatural Language Processing and its Use in Education\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>\\n                  Neural Network Computing and Natural Language Processing*\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>\\n                  Text Statistics Tool Box For Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>\\n                  Using Frame Semantics in Natural Language Processing\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                        Titles\n",
              "0                                                                                 \\n                  Foundations of statistical natural language processing\\n\n",
              "1                                                                              \\n                  A Maximum Entropy approach to Natural Language Processing\\n\n",
              "2                                                                                                                              \\nNatural Language Processing\\n\n",
              "3                                                                                            \\n                  Linguistics and Natural Language Processing\\n\n",
              "4                                                                                                                              \\nNatural Language Processing\\n\n",
              "5                                                                                     \\nNatural language processing (almost) from scratch \\n                  \n",
              "6                                                                                                                              \\nNatural language processing\\n\n",
              "7                                                                                                   \\nNatural Language Processing/Robotics\\n                  \n",
              "8                                                                                                \\n                  Tutorial on Natural Language Processing\\n\n",
              "9                                                                                             \\n                  Ambiguities in Natural Language Processing\\n\n",
              "10                                                                                               \\n                  Statistical Natural Language Processing\\n\n",
              "11                                                                                 \\nNatural Language Processing for Information Retrieval\\n                  \n",
              "12                                                                                                                             \\nNatural Language Processing\\n\n",
              "13                                                                                                 \\nNatural language processing of lyrics\\n                  \n",
              "14  \\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  \n",
              "15                                                                                             \\n                  Connectionist Natural Language Processing\\n\n",
              "16                                                                                                 \\n                  Chaos and Natural Language Processing\\n\n",
              "17                                                                                                          \\nNatural Language Processing:\\n                  \n",
              "18                                                                                          \\nNatural language processing: an introduction\\n                  \n",
              "19                                                                                               \\n                  Overview of Natural Language Processing\\n\n",
              "20                                                                                                                             \\nNatural Language Processing\\n\n",
              "21                                                                      \\n                  Evaluating Natural Language Processing Systems\\n                  \n",
              "22                                                                                              \\n                  Analysis and Natural Language Processing\\n\n",
              "23                                                                                            \\nNatural Language Processing using NLTK and\\n                  \n",
              "24                                                                                \\nNatural Language Processing Complexity and Parallelism\\n                  \n",
              "25                                                                     \\n                  Large Lexicons For Natural Language Processing:\\n                  \n",
              "26                                                                                 \\nNatural Language Processing: Structure and Complexity\\n                  \n",
              "27                                                                                         \\n                  Deep Learning for Natural Language Processing\\n\n",
              "28                                                                                                                             \\nNatural Language Processing\\n\n",
              "29                                                                                   \\nNatural Language Processing of Textual Requirements\\n                  \n",
              "..                                                                                                                                                         ...\n",
              "70                                                        \\n                   An Overview of Probabilistic Tree Transducers for Natural Language Processing\\n\n",
              "71                                                                               \\n                  Principles of Evaluation in Natural Language Processing\\n\n",
              "72                                                                                      \\nNatural Language Processing with ThoughtTreasure\\n                  \n",
              "73                                                                 \\n                  A broad-coverage natural language processing system\\n                  \n",
              "74                                                                                     \\n                  Logic Programming for Natural Language Processing\\n\n",
              "75                \\n                  A unified architecture for natural language processing: Deep neural networks with multitask learning\\n                  \n",
              "76                                                                        \\n                  Information Retrieval Using Robust Natural Language Processing\\n\n",
              "77                                                                                  \\n                  An overview of empirical natural language processing\\n\n",
              "78                                                       \\n                  Towards Context-adaptive Natural Language Processing Systems \\n                  \n",
              "79                                             \\n                  Teaching Applied Natural Language Processing: Triumphs and Tribulations\\n                  \n",
              "80                                                                                  \\n                  On Memory Limitations In Natural Language Processing\\n\n",
              "81                                                             \\nNatural Language Processing: An approach to Parsing and Semantic Analysis\\n                  \n",
              "82                                                    \\n                  A REVIEW ON THE PROGRESS OF NATURAL LANGUAGE PROCESSING IN INDIA\\n                  \n",
              "83                                             \\n                  An Evaluation of LOLITA and Related Natural Language Processing Systems\\n                  \n",
              "84                                                                                      \\n                  Web-based models for natural language processing\\n\n",
              "85                                                                   \\n                  Computer-Assisted Language Learning And Natural Language Processing\\n\n",
              "86                                                                                     \\n                  Learning schemata for natural language processing\\n\n",
              "87                                                                               \\n                  Software Infrastructure for Natural Language Processing\\n\n",
              "88                                               \\n                  1. CONFIDENCE ESTIMATION FOR NATURAL LANGUAGE PROCESSING APPLICATIONS\\n                  \n",
              "89                                                                                         \\n                  Lexical Issues in Natural Language Processing\\n\n",
              "90                                                            \\n                  The Stanford CoreNLP Natural Language Processing Toolkit\\n                  \n",
              "91                                                                                    \\n                  Gaussian Processes for Natural Language Processing\\n\n",
              "92                                            \\n                  An Historical Overview of Natural Language Processing Systems That Learn\\n                  \n",
              "93                                                                  \\n                  Upper Modeling: organizing knowledge for natural language processing\\n\n",
              "94                                                                                   \\n                  Self-Organizing Maps In Natural Language Processing\\n\n",
              "95                                                        \\n                  A Workbench for Developing Natural Language Processing Tools\\n                  \n",
              "96                                                                                  \\nNatural Language Processing and its Use in Education\\n                  \n",
              "97                                                           \\n                  Neural Network Computing and Natural Language Processing*\\n                  \n",
              "98                                                                              \\n                  Text Statistics Tool Box For Natural Language Processing\\n\n",
              "99                                                                                  \\n                  Using Frame Semantics in Natural Language Processing\\n\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxYG78hHvc2O"
      },
      "source": [
        "word=\"\"\n",
        "for i in df.values:\n",
        "  word+=i[0]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "fxJpYI_Ovrdy",
        "outputId": "7f3adfc4-a925-4f56-87d6-d240c2d57fc7"
      },
      "source": [
        "word"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n                  Foundations of statistical natural language processing\\n\\n                  A Maximum Entropy approach to Natural Language Processing\\n\\nNatural Language Processing\\n\\n                  Linguistics and Natural Language Processing\\n\\nNatural Language Processing\\n\\nNatural language processing (almost) from scratch \\n                  \\nNatural language processing\\n\\nNatural Language Processing/Robotics\\n                  \\n                  Tutorial on Natural Language Processing\\n\\n                  Ambiguities in Natural Language Processing\\n\\n                  Statistical Natural Language Processing\\n\\nNatural Language Processing for Information Retrieval\\n                  \\nNatural Language Processing\\n\\nNatural language processing of lyrics\\n                  \\n                  Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging\\n                  \\n                  Connectionist Natural Language Processing\\n\\n                  Chaos and Natural Language Processing\\n\\nNatural Language Processing:\\n                  \\nNatural language processing: an introduction\\n                  \\n                  Overview of Natural Language Processing\\n\\nNatural Language Processing\\n\\n                  Evaluating Natural Language Processing Systems\\n                  \\n                  Analysis and Natural Language Processing\\n\\nNatural Language Processing using NLTK and\\n                  \\nNatural Language Processing Complexity and Parallelism\\n                  \\n                  Large Lexicons For Natural Language Processing:\\n                  \\nNatural Language Processing: Structure and Complexity\\n                  \\n                  Deep Learning for Natural Language Processing\\n\\nNatural Language Processing\\n\\nNatural Language Processing of Textual Requirements\\n                  \\nNatural Language Processing and Information Retrieval\\n                  \\nNatural language processing\\n\\nNatural Language Processing\\n\\nNatural Language Processing\\n\\n                  Ants for Natural Language Processing\\n\\n                  ontologies, natural language processing\\n\\nNatural language processing\\n\\n                  Retrieval or Natural Language Processing\\n\\n                  THESAURUSES FOR NATURAL LANGUAGE PROCESSING\\n\\nNatural Language Processing\\n\\nNatural Language Processing Section\\n                  \\nNatural Language Processing for\\n                  \\nNatural Language Processing Group\\n                  \\n                  BIOMEDICAL NATURAL LANGUAGE PROCESSING\\n\\n                  learning in Natural Language Processing\\n\\n                  An Introduction to Natural Language Processing\\n\\nNatural Language Processing 2\\n                  \\n                  Integrating speech and natural-language processing\\n\\n                  Paradigm Merger in Natural Language Processing\\n\\n                  on Visual Tools for Natural Language Processing\\n\\n                  Description Logics for Natural Language Processing\\n\\n                  STRUCTURE LEARNING FOR NATURAL LANGUAGE PROCESSING\\n\\n                  Commercial applications of natural language processing\\n\\n                  2008. Networks and natural language processing\\n\\n                  Current Issues in Software Engineering for Natural Language Processing\\n\\n                  Kernelized Sorting for Natural Language Processing\\n\\n                  Distributional Approaches to Natural Language Processing\\n\\n                  Decomposable Modeling in Natural Language Processing\\n\\nNatural Language Processing in Information Retrieval\\n                  \\n                  Information Retrieval in Malayalam Using Natural Language Processing\\n\\n                  On Natural Language Processing and Plan Recognition\\n                  \\n                  On Natural Language Processing and Plan Recognition\\n                  \\nNatural Language Processing in Information Retrieval\\n                  \\n                  Induction, Logic, and Natural Language Processing\\n\\n                  On Statistical Methods in Natural Language Processing\\n\\n                  Machine Learning and Natural Language Processing\\n\\n                  Machine Learning in Natural Language Processing\\n\\nNatural Language Processing In Computer-Assisted Language Learning\\n                  \\n                  SESSION 9: NATURAL LANGUAGE PROCESSINGS\\n\\nNatural Language Processing: A Survey\\n                  \\n                   An Overview of Probabilistic Tree Transducers for Natural Language Processing\\n\\n                  Principles of Evaluation in Natural Language Processing\\n\\nNatural Language Processing with ThoughtTreasure\\n                  \\n                  A broad-coverage natural language processing system\\n                  \\n                  Logic Programming for Natural Language Processing\\n\\n                  A unified architecture for natural language processing: Deep neural networks with multitask learning\\n                  \\n                  Information Retrieval Using Robust Natural Language Processing\\n\\n                  An overview of empirical natural language processing\\n\\n                  Towards Context-adaptive Natural Language Processing Systems \\n                  \\n                  Teaching Applied Natural Language Processing: Triumphs and Tribulations\\n                  \\n                  On Memory Limitations In Natural Language Processing\\n\\nNatural Language Processing: An approach to Parsing and Semantic Analysis\\n                  \\n                  A REVIEW ON THE PROGRESS OF NATURAL LANGUAGE PROCESSING IN INDIA\\n                  \\n                  An Evaluation of LOLITA and Related Natural Language Processing Systems\\n                  \\n                  Web-based models for natural language processing\\n\\n                  Computer-Assisted Language Learning And Natural Language Processing\\n\\n                  Learning schemata for natural language processing\\n\\n                  Software Infrastructure for Natural Language Processing\\n\\n                  1. CONFIDENCE ESTIMATION FOR NATURAL LANGUAGE PROCESSING APPLICATIONS\\n                  \\n                  Lexical Issues in Natural Language Processing\\n\\n                  The Stanford CoreNLP Natural Language Processing Toolkit\\n                  \\n                  Gaussian Processes for Natural Language Processing\\n\\n                  An Historical Overview of Natural Language Processing Systems That Learn\\n                  \\n                  Upper Modeling: organizing knowledge for natural language processing\\n\\n                  Self-Organizing Maps In Natural Language Processing\\n\\n                  A Workbench for Developing Natural Language Processing Tools\\n                  \\nNatural Language Processing and its Use in Education\\n                  \\n                  Neural Network Computing and Natural Language Processing*\\n                  \\n                  Text Statistics Tool Box For Natural Language Processing\\n\\n                  Using Frame Semantics in Natural Language Processing\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NxZKwF2yKhb"
      },
      "source": [
        "import nltk \n",
        "import spacy \n",
        "import math  \n",
        "import string  \n",
        "from tqdm import tqdm \n",
        "from spacy.matcher import Matcher \n",
        "from spacy import displacy\n",
        "from spacy.tokens import Span \n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np \n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNmhtazezZu4",
        "outputId": "5046194f-6c51-478b-ae04-bbc84737fb89"
      },
      "source": [
        "document = nlp(word)\n",
        "\n",
        "# print dependency tags and POS tags\n",
        "for token in document: \n",
        "  print(token.text, \"-->\",token.dep_, \"-->\",token.pos_)\n",
        "\n",
        "# Matcher class object \n",
        "matcher = Matcher(nlp.vocab) \n",
        "\n",
        "#define the pattern \n",
        "dataSet = [{'DEP':'amod', 'OP':\"?\"}, \n",
        "           {'POS':'NOUN'}, \n",
        "           {'LOWER': 'and', 'OP':\"?\"}, \n",
        "           {'LOWER': 'or', 'OP':\"?\"}, \n",
        "           {'LOWER': 'other'}, \n",
        "           {'POS': 'NOUN'}] \n",
        "           \n",
        "matcher.add(\"matching_1\", None, dataSet) \n",
        "\n",
        "finalData = matcher(document) \n",
        "finalData"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                   -->  --> SPACE\n",
            "Foundations --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "statistical --> amod --> ADJ\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "Maximum --> compound --> ADJ\n",
            "Entropy --> compound --> ADJ\n",
            "approach --> dobj --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Linguistics --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> ROOT --> NOUN\n",
            "( --> punct --> PUNCT\n",
            "almost --> advmod --> ADV\n",
            ") --> punct --> PUNCT\n",
            "from --> prep --> ADP\n",
            "scratch --> nmod --> NOUN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "/ --> punct --> SYM\n",
            "Robotics --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Tutorial --> ROOT --> PROPN\n",
            "on --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Ambiguities --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Statistical --> compound --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "lyrics --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Transformation --> npadvmod --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Based --> amod --> PROPN\n",
            "Error --> npadvmod --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Driven --> nmod --> VERB\n",
            "Learning --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "Case --> compound --> PROPN\n",
            "Study --> ROOT --> PROPN\n",
            "in --> prep --> ADP\n",
            "Part --> nmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "of --> prep --> ADP\n",
            "- --> punct --> PUNCT\n",
            "Speech --> pobj --> NOUN\n",
            "Tagging --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Connectionist --> compound --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Chaos --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> conj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> appos --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "an --> det --> DET\n",
            "introduction --> appos --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Overview --> conj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Evaluating --> nmod --> VERB\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Systems --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Analysis --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "NLTK --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Complexity --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Parallelism --> conj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Large --> amod --> ADJ\n",
            "Lexicons --> dobj --> NOUN\n",
            "For --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> appos --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "Structure --> appos --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Complexity --> conj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Deep --> compound --> ADJ\n",
            "Learning --> conj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Textual --> compound --> PROPN\n",
            "Requirements --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Information --> conj --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Ants --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "ontologies --> pobj --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> conj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> amod --> ADJ\n",
            "language --> nmod --> NOUN\n",
            "processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Retrieval --> conj --> PROPN\n",
            "or --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> amod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "THESAURUSES --> ROOT --> NOUN\n",
            "FOR --> prep --> ADP\n",
            "NATURAL --> amod --> ADJ\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSING --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Section --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "for --> prep --> ADP\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Group --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "BIOMEDICAL --> compound --> PROPN\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> nsubj --> PROPN\n",
            "PROCESSING --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "learning --> ROOT --> VERB\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "An --> det --> DET\n",
            "Introduction --> ROOT --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> acl --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "2 --> nummod --> NUM\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Integrating --> compound --> VERB\n",
            "speech --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "natural --> amod --> ADJ\n",
            "- --> punct --> PUNCT\n",
            "language --> conj --> NOUN\n",
            "processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Paradigm --> compound --> PROPN\n",
            "Merger --> conj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "on --> prep --> ADP\n",
            "Visual --> compound --> ADJ\n",
            "Tools --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Description --> compound --> PROPN\n",
            "Logics --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "STRUCTURE --> compound --> PROPN\n",
            "LEARNING --> pobj --> NOUN\n",
            "FOR --> prep --> ADP\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSING --> nmod --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Commercial --> amod --> ADJ\n",
            "applications --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pcomp --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "2008 --> npadvmod --> NUM\n",
            ". --> punct --> PUNCT\n",
            "Networks --> nsubj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "natural --> amod --> ADJ\n",
            "language --> conj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Current --> compound --> PROPN\n",
            "Issues --> dobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Software --> compound --> PROPN\n",
            "Engineering --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Kernelized --> compound --> VERB\n",
            "Sorting --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Distributional --> compound --> ADJ\n",
            "Approaches --> pobj --> NOUN\n",
            "to --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Decomposable --> compound --> ADJ\n",
            "Modeling --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Malayalam --> pobj --> PROPN\n",
            "Using --> ROOT --> VERB\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Plan --> conj --> PROPN\n",
            "Recognition --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "Natural --> nmod --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Plan --> conj --> PROPN\n",
            "Recognition --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nsubj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Induction --> pobj --> PROPN\n",
            ", --> punct --> PUNCT\n",
            "Logic --> conj --> PROPN\n",
            ", --> punct --> PUNCT\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> pcomp --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "Statistical --> amod --> PROPN\n",
            "Methods --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Machine --> compound --> NOUN\n",
            "Learning --> nmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Machine --> compound --> NOUN\n",
            "Learning --> pobj --> VERB\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> ADJ\n",
            "Language --> compound --> NOUN\n",
            "Processing --> nsubj --> NOUN\n",
            "In --> prep --> ADP\n",
            "Computer --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Assisted --> amod --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Learning --> pobj --> VERB\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "SESSION --> ROOT --> NOUN\n",
            "9 --> nummod --> NUM\n",
            ": --> punct --> PUNCT\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSINGS --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "Survey --> appos --> PROPN\n",
            "\n",
            "                  \n",
            "                    -->  --> SPACE\n",
            "An --> det --> DET\n",
            "Overview --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "Probabilistic --> compound --> ADJ\n",
            "Tree --> compound --> PROPN\n",
            "Transducers --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Principles --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Evaluation --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            "with --> prep --> ADP\n",
            "ThoughtTreasure --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "broad --> amod --> ADJ\n",
            "- --> punct --> PUNCT\n",
            "coverage --> nmod --> NOUN\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> compound --> NOUN\n",
            "system --> ROOT --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Logic --> compound --> PROPN\n",
            "Programming --> appos --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "unified --> amod --> VERB\n",
            "architecture --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> compound --> NOUN\n",
            "processing --> pobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "Deep --> amod --> ADJ\n",
            "neural --> amod --> ADJ\n",
            "networks --> ROOT --> NOUN\n",
            "with --> prep --> ADP\n",
            "multitask --> compound --> NOUN\n",
            "learning --> pcomp --> VERB\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Information --> compound --> PROPN\n",
            "Retrieval --> ROOT --> PROPN\n",
            "Using --> acl --> PROPN\n",
            "Robust --> compound --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "An --> det --> DET\n",
            "overview --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "empirical --> amod --> ADJ\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Towards --> prep --> ADP\n",
            "Context --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "adaptive --> amod --> ADJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Systems --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Teaching --> pobj --> PROPN\n",
            "Applied --> acl --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> dobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "Triumphs --> appos --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Tribulations --> conj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "Memory --> compound --> PROPN\n",
            "Limitations --> pobj --> NOUN\n",
            "In --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> nmod --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "An --> det --> DET\n",
            "approach --> ROOT --> NOUN\n",
            "to --> prep --> ADP\n",
            "Parsing --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Semantic --> compound --> ADJ\n",
            "Analysis --> conj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "REVIEW --> ROOT --> NOUN\n",
            "ON --> prep --> ADP\n",
            "THE --> det --> DET\n",
            "PROGRESS --> pobj --> PROPN\n",
            "OF --> prep --> ADP\n",
            "NATURAL --> amod --> PROPN\n",
            "LANGUAGE --> compound --> PROPN\n",
            "PROCESSING --> pobj --> NOUN\n",
            "IN --> prep --> ADP\n",
            "INDIA --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "An --> det --> DET\n",
            "Evaluation --> ROOT --> PROPN\n",
            "of --> prep --> ADP\n",
            "LOLITA --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Related --> conj --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Systems --> nmod --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Web --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "based --> amod --> VERB\n",
            "models --> conj --> NOUN\n",
            "for --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Computer --> npadvmod --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Assisted --> nmod --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Learning --> dobj --> PROPN\n",
            "And --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> appos --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Learning --> compound --> VERB\n",
            "schemata --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Software --> compound --> NOUN\n",
            "Infrastructure --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "1 --> nummod --> NUM\n",
            ". --> punct --> PUNCT\n",
            "CONFIDENCE --> compound --> NOUN\n",
            "ESTIMATION --> ROOT --> NOUN\n",
            "FOR --> prep --> ADP\n",
            "NATURAL --> amod --> ADJ\n",
            "LANGUAGE --> compound --> NOUN\n",
            "PROCESSING --> compound --> NOUN\n",
            "APPLICATIONS --> pobj --> NOUN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Lexical --> compound --> PROPN\n",
            "Issues --> nsubj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "The --> det --> DET\n",
            "Stanford --> nmod --> PROPN\n",
            "CoreNLP --> punct --> PROPN\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> NOUN\n",
            "Toolkit --> appos --> VERB\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Gaussian --> compound --> ADJ\n",
            "Processes --> ROOT --> PROPN\n",
            "for --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "An --> det --> DET\n",
            "Historical --> compound --> ADJ\n",
            "Overview --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Systems --> pobj --> PROPN\n",
            "That --> nsubj --> DET\n",
            "Learn --> relcl --> VERB\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Upper --> compound --> PROPN\n",
            "Modeling --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "organizing --> acl --> VERB\n",
            "knowledge --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "natural --> amod --> ADJ\n",
            "language --> pobj --> NOUN\n",
            "processing --> acl --> NOUN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Self --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Organizing --> amod --> NOUN\n",
            "Maps --> dobj --> PROPN\n",
            "In --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> pobj --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "A --> det --> DET\n",
            "Workbench --> dobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "Developing --> nmod --> VERB\n",
            "Natural --> compound --> PROPN\n",
            "Language --> nmod --> PROPN\n",
            "Processing --> compound --> PROPN\n",
            "Tools --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            " -->  --> SPACE\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "its --> poss --> DET\n",
            "Use --> conj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Education --> pobj --> PROPN\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Neural --> compound --> PROPN\n",
            "Network --> compound --> PROPN\n",
            "Computing --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Natural --> compound --> PROPN\n",
            "Language --> conj --> PROPN\n",
            "Processing --> ROOT --> PROPN\n",
            "* --> ROOT --> PUNCT\n",
            "\n",
            "                  \n",
            "                   -->  --> SPACE\n",
            "Text --> compound --> NOUN\n",
            "Statistics --> compound --> NOUN\n",
            "Tool --> compound --> PROPN\n",
            "Box --> ROOT --> PROPN\n",
            "For --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            "\n",
            "                   -->  --> SPACE\n",
            "Using --> ROOT --> VERB\n",
            "Frame --> compound --> PROPN\n",
            "Semantics --> dobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "Natural --> compound --> PROPN\n",
            "Language --> compound --> PROPN\n",
            "Processing --> pobj --> PROPN\n",
            "\n",
            " -->  --> SPACE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., â€œsection 1 of the Advancing Hope Act, 1986â€\n",
        "\n",
        "(2) amounts, e.g., â€œten poundsâ€ or â€œ5.8 megawattsâ€\n",
        "\n",
        "(3) citations, e.g., â€œ10 U.S. 100â€ or â€œ1998 S. Ct. 1â€\n",
        "\n",
        "(4) companies, e.g., â€œLexpredict LLCâ€\n",
        "\n",
        "(5) conditions, e.g., â€œsubject to â€¦â€ or â€œunless and until â€¦â€\n",
        "\n",
        "(6) constraints, e.g., â€œno more thanâ€\n",
        "\n",
        "(7) copyright, e.g., â€œ(C) Copyright 2000 Acmeâ€\n",
        "\n",
        "(8) courts, e.g., â€œSupreme Court of New Yorkâ€\n",
        "\n",
        "(9) CUSIP, e.g., â€œ392690QT3â€\n",
        "\n",
        "(10) dates, e.g., â€œJune 1, 2017â€ or â€œ2018-01-01â€\n",
        "\n",
        "(11) definitions, e.g., â€œTerm shall mean â€¦â€\n",
        "\n",
        "(12) distances, e.g., â€œfifteen milesâ€\n",
        "\n",
        "(13) durations, e.g., â€œten yearsâ€ or â€œthirty daysâ€\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., â€œNew Yorkâ€ or â€œNorwayâ€\n",
        "\n",
        "(15) money and currency usages, e.g., â€œ$5â€ or â€œ10 Euroâ€\n",
        "\n",
        "(16) percents and rates, e.g., â€œ10%â€ or â€œ50 bpsâ€\n",
        "\n",
        "(17) PII, e.g., â€œ212-212-2121â€ or â€œ999-999-9999â€\n",
        "\n",
        "(18) ratios, e.g.,â€ 3:1â€ or â€œfour to threeâ€\n",
        "\n",
        "(19) regulations, e.g., â€œ32 CFR 170â€\n",
        "\n",
        "(20) trademarks, e.g., â€œMyApp (TM)â€\n",
        "\n",
        "(21) URLs, e.g., â€œhttp://acme.com/â€\n",
        "\n",
        "(22) addresses, e.g., â€œ1999 Mount Read Blvd, Rochester, NY, USA, 14615â€\n",
        "\n",
        "(23) persons, e.g., â€œJohn Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc7NtJrLx5tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acf3b0d-f1cf-4200-b0d2-cb8b261a6191"
      },
      "source": [
        "!pip install lexnlp"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lexnlp in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: datefinder-lexpredict==0.6.2.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.6.2.1)\n",
            "Requirement already satisfied: us==2.0.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.2)\n",
            "Requirement already satisfied: pycountry==20.7.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (20.7.3)\n",
            "Requirement already satisfied: dateparser==0.7.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.7.2)\n",
            "Requirement already satisfied: joblib==0.14.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.14.0)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.24.0)\n",
            "Requirement already satisfied: regex==2020.7.14 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2020.7.14)\n",
            "Requirement already satisfied: reporters-db==2.0.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.3)\n",
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.19.1)\n",
            "Requirement already satisfied: scipy==1.5.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.5.1)\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.8.3)\n",
            "Requirement already satisfied: scikit-learn==0.23.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.23.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.24.2)\n",
            "Requirement already satisfied: Unidecode==1.1.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.1.1)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.5)\n",
            "Requirement already satisfied: num2words==0.5.10 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.5.10)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->lexnlp) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->lexnlp) (2.8.1)\n",
            "Requirement already satisfied: jellyfish==0.6.1 in /usr/local/lib/python3.7/dist-packages (from us==2.0.2->lexnlp) (0.6.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2020.12.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==2.0.3->lexnlp) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (4.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1->lexnlp) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (4.41.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp2Dl1YK3ECI"
      },
      "source": [
        "text_data = open(\"/content/sample_data/excercise6.txt\").read()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qGTxGmI4lDG",
        "outputId": "8a11e70c-e065-44b3-f13d-347e141f7674"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51GRfHnE4ouN",
        "outputId": "73983825-313e-4afa-bfba-16ce777be80d"
      },
      "source": [
        "import lexnlp.extract.en.amounts\n",
        "list(lexnlp.extract.en.amounts.get_amounts(text_data))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Decimal('5.0'),\n",
              " Decimal('740.0'),\n",
              " Decimal('1843.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('1821.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('1840.0'),\n",
              " Decimal('3777.0'),\n",
              " Decimal('80.0'),\n",
              " Decimal('100.0'),\n",
              " Decimal('30.0'),\n",
              " Decimal('1839.0'),\n",
              " Decimal('741.0'),\n",
              " Decimal('22.0'),\n",
              " Decimal('1840.0'),\n",
              " Decimal('14000.0'),\n",
              " Decimal('120.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('1840.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('1840.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('361.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('307.0'),\n",
              " Decimal('6.0'),\n",
              " Decimal('604.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('418.0'),\n",
              " Decimal('422.0'),\n",
              " Decimal('7.0'),\n",
              " Decimal('34.0'),\n",
              " Decimal('41.0'),\n",
              " Decimal('167.0'),\n",
              " Decimal('742.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('112.0'),\n",
              " Decimal('207.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('338.0'),\n",
              " Decimal('424.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('26.0'),\n",
              " Decimal('13.0'),\n",
              " Decimal('235.0'),\n",
              " Decimal('8.0'),\n",
              " Decimal('693.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('1821.0'),\n",
              " Decimal('167.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('216.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('66.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('130.0'),\n",
              " Decimal('29.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('241.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('332.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('422.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('112.0'),\n",
              " Decimal('743.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('39.0'),\n",
              " Decimal('14000.0'),\n",
              " Decimal('1840.0'),\n",
              " Decimal('744.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('182.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('368.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('397.0'),\n",
              " Decimal('6.0'),\n",
              " Decimal('604.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('1821.0'),\n",
              " Decimal('167.0'),\n",
              " Decimal('745.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('746.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('210.0'),\n",
              " Decimal('46.0'),\n",
              " Decimal('747.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('740.0'),\n",
              " Decimal('1843.0'),\n",
              " Decimal('284.0'),\n",
              " Decimal('2019.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('55.0'),\n",
              " Decimal('266.0'),\n",
              " Decimal('271.0'),\n",
              " Decimal('1876.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('47.0'),\n",
              " Decimal('362.0'),\n",
              " Decimal('376.0'),\n",
              " Decimal('1872.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('45.0'),\n",
              " Decimal('329.0'),\n",
              " Decimal('334.0'),\n",
              " Decimal('1871.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('31.0'),\n",
              " Decimal('526.0'),\n",
              " Decimal('527.0'),\n",
              " Decimal('1858.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('21.0'),\n",
              " Decimal('333.0'),\n",
              " Decimal('335.0'),\n",
              " Decimal('1852.0'),\n",
              " Decimal('6.0'),\n",
              " Decimal('8.0'),\n",
              " Decimal('145.0'),\n",
              " Decimal('147.0'),\n",
              " Decimal('1857.0'),\n",
              " Decimal('7.0'),\n",
              " Decimal('65.0'),\n",
              " Decimal('256.0'),\n",
              " Decimal('258.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('1880.0'),\n",
              " Decimal('8.0'),\n",
              " Decimal('4.0'),\n",
              " Decimal('913.0'),\n",
              " Decimal('914.0'),\n",
              " Decimal('1887.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('103.0'),\n",
              " Decimal('464.0'),\n",
              " Decimal('1936.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('39.0'),\n",
              " Decimal('1828.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('5.0'),\n",
              " Decimal('182.0'),\n",
              " Decimal('1837.0'),\n",
              " Decimal('2.0'),\n",
              " Decimal('3.0'),\n",
              " Decimal('9.0'),\n",
              " Decimal('108.0'),\n",
              " Decimal('1812.0'),\n",
              " Decimal('6.0'),\n",
              " Decimal('1.0'),\n",
              " Decimal('2.0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYAWjcg14x5k",
        "outputId": "983a9e06-e5e3-43ec-a56e-7e775413f63c"
      },
      "source": [
        "import lexnlp.extract.en.citations\n",
        "print(list(lexnlp.extract.en.citations.get_citations(text_data)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(5, 'Ala.', 'Alabama Reports', 740, None, None, None), (5, 'Ala.', 'Alabama Reports', 740, '1843', None, None), (55, 'Ala.', 'Alabama Reports', 266, '271', None, None), (47, 'Ala.', 'Alabama Reports', 362, '376', None, None), (45, 'Ala.', 'Alabama Reports', 329, '334', None, None), (31, 'Ala.', 'Alabama Reports', 526, '527', None, None), (21, 'Ala.', 'Alabama Reports', 333, '335', None, None), (8, 'Cal.', 'California Reports', 145, '147', None, None), (65, 'Ala.', 'Alabama Reports', 256, '258', None, None), (4, 'S.W.', 'South Western Reporter', 913, '914', None, None), (103, 'A.L.R.', 'American Law Reports', 464, None, None, None), (9, 'Cow.', \"Cowen's Reports\", 39, None, None, None), (5, 'Port.', 'Alabama Reports, Porter', 182, None, None, None), (9, 'Johns.', \"Johnson's Reports\", 108, None, None, None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP_g2VIj410t",
        "outputId": "e37dd5cc-a2fa-43dc-b359-4b4f5263694a"
      },
      "source": [
        "import lexnlp.extract.en.entities.nltk_re\n",
        "print(list(lexnlp.extract.en.entities.nltk_re.get_companies(text_data)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Lehman, Durr Co, (17983, 18001)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_zWV0T6455q",
        "outputId": "c0a04653-23d7-426a-8533-2714a67e5b63"
      },
      "source": [
        "import lexnlp.extract.en.conditions\n",
        "print(list(lexnlp.extract.en.conditions.get_conditions(text_data)))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('until', '[2]\\nCreditorsâ€™ Remedies\\nLien and Priority\\nUnder St.1821, prohibiting a levy on a crop', ''), ('until', 'on a growing crop, nor does such lien attach', ''), ('if', 'It was proved by the claimants, by the production of a written contract, that Harrison, on the twenty-second of May, 1840, in consideration that the claimants were involved, as indorsers for Burton & Harrison of Sumter county, and were then exposed to an execution, amounting to upwards of fourteen thousand dollars, bargained and sold to the claimants all his growing crop of cotton &c., consisting of one hundred and twenty acres, &c. Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers;', ''), ('when', 'The claimants came from Tennessee, (where they resided) about the first of September, 1840, bringing with them three or four white laborers, and took possession of the crop and slaves, and with the latter, and white laborers, gathered the cotton, prepared it for market, and', ''), ('if', 'The court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that Harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but', ''), ('when', 'it was not, and the lien of the fieri facias would have attached upon it,', ''), ('if', 'gathered, yet', ''), ('not subject to', 'the claimants obtained possession on the first of September, and controlled the gathering of the crop, then no lien attached, and it was', ''), ('until', 'Rep, 693;] and', ''), ('until', '167,] which declares it to be lawful to levy an execution on a planted crop,', ''), ('if', 'It is admitted that the contract between the defendant in execution, and the claimants, was in good faith,', ''), ('when', 'The defendant in execution might at any time have divested the interest which the contract vested in the claimants, by discharging their liability as his indorsers, or a judgment creditor might have satisfied the lien, and', ''), ('unless', 'We will then consider the writing under which the claimants assert a right, as a mortgage with a power to take possession any time during the year,', ''), ('if', 'Conceding the truth of the facts stated in the bill of exceptions, and we think it will not follow, that the possession of the claimants is a nullity, and that the case must be considered as', ''), ('if', 'The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity, and', ''), ('if', 'they took possession of it in the absence of the grantor, (though without his consent,)', ''), ('if', 'he subsequently acquiesced in it, the inference would be,', ''), ('subject to', 'Mr. Dane, in remarking upon this point, says, â€œThe American editor of Baconâ€™s Abridgment, says, â€˜Wheat growing in the ground is a chattel, and', ''), ('until', 'The first section of the act of 1821, â€œTo prevent sheriffs and other officers from levying executions in certain cases, enacts, that â€œIt shall not be lawful for any sheriff or other officer, to levy a writ of fieri facias or other execution on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('until', 'Now here is an express inhibition to levy an execution on a crop while it remains on, or in the ground, and', ''), ('until', 'If so, the act cited, will only have the effect of keeping the right to levy it in abeyance', ''), ('if', 'The lien and the right to levy are intimately connected, and', ''), ('until', 'That it was competent for the legislature to have made it unlawful to levy an execution on particular property,', ''), ('until', 'If the object was merely to suspend the sale,', ''), ('as soon as', 'The idea that the lien attached upon the planted crop', ''), ('until', 'the execution was delivered to the sheriff, though the right to levy it was postponed', ''), ('if', 'They do not refer to the lien,', ''), ('until', 'they did they would postpone it', ''), ('until', 'the crop was gathered; but it is the levy they relate to and postpone', ''), ('until', '**4 The right to levy an execution on a planted crop, then, being expressly taken away by the statute, the lien which is connected with and consequent upon that right, never attaches', ''), ('if', 'The circuit judge may have mistaken the law in supposing that the contract was a sale, but', ''), ('when', 'There is no assumption of any material fact in the charge; but the possession of the claimant, the time', ''), ('if', 'acquired, the gathering of the crop, &c., are all referred to the determination of the jury; who are instructed,', ''), ('until', '**4 The statute which presents the question before the court is, that â€œit shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution, on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('subject to', 'The policy of the State, as indicated by these statutes, is undeniably that all the property of a debtor, real and personal, to which he has a legal title, shall be', ''), ('until', 'The mischief which the statute designed to remedy was, the sacrifice which would be necessarily made by the sale of an immature crop: the statute enables the debtor to retain it', ''), ('if', '**5', ''), ('until', 'The sheriff is forbidden to levy on a â€œplanted cropâ€', ''), ('if', 'Now,', ''), ('until', 'This, I feel a thorough conviction, was not the intention of the legislature; but that it was to secure him from loss, by prohibiting a levy and sale of the crop,', ''), ('when', 'it was gathered,', ''), ('subject to', 'Growing crops as', ''), ('subject to', '464\\nGenerally, at common law, growing crops raised by annual planting, while still attached to the soil, are regarded as personal chattels,', ''), ('where', 'And', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whZHH7oa49vp",
        "outputId": "e33e411f-8a7e-45b4-8b35-77202628ab34"
      },
      "source": [
        "import lexnlp.extract.en.constraints\n",
        "print(list(lexnlp.extract.en.constraints.get_constraints(text_data)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('after', 'on a growing crop, nor does such lien attach until', ''), ('after', '', ' and that alias and pluries fieri faciasâ€™, issued regularly up to the time levy was made; that the cotton levied on was growed on the plantation of harrison, and cultivated by the hands in his service.'), ('first of', 'the claimants came from tennessee, (where they resided) about the', ''), ('first of', 'the court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but if it was not, and the lien of the fieri facias would have attached upon it, when gathered, yet if the claimants obtained possession on the', ''), ('after', 'it merely inhibits the levy, but the lien attaches, and a levy and sale may be made', ''), ('more than', 'taking this to be clear *744 law, and it will be seen, that the defendant in execution at the time of the levy had nothing', ''), ('before', 'it has been frequently mooted whether, at common law, corn, &c.,', ''), ('before', '**4 the statute which presents the question', ''), ('after', 'now, if the view taken by the majority of the court, is correct, the right secured to the plaintiff in execution, of levying on the crop', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzAnec8P4-pd",
        "outputId": "d4fa08ac-c705-45c0-c3ab-c0de87e1d92a"
      },
      "source": [
        "import lexnlp.extract.en.copyright\n",
        "print(list(lexnlp.extract.en.copyright.get_copyright(text_data)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Â©', '2019', 'Thomson Reuters. No')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ScFA-P35CMN",
        "outputId": "99d0fa7e-1a2f-402c-944b-8ff44caf69eb"
      },
      "source": [
        "import lexnlp.extract.en.courts\n",
        "court_config_data = []\n",
        "print(list(lexnlp.extract.en.courts.get_courts(text_data,court_config_data)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmwVK9nH5FVA",
        "outputId": "e8f43d15-7a88-48a7-adf4-a0112eb8add3"
      },
      "source": [
        "import lexnlp.extract.en.cusip\n",
        "print(lexnlp.extract.en.cusip.get_cusip(text_data))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object get_cusip at 0x7ff019e0e0d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDMG36xa5Haq",
        "outputId": "7ed0e291-6d68-45a0-b91d-569eba1b7854"
      },
      "source": [
        "import lexnlp.extract.en.dates\n",
        "print(list(lexnlp.extract.en.dates.get_dates(text_data)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[datetime.date(2021, 6, 1), datetime.date(1840, 11, 1), datetime.date(1839, 10, 1), datetime.date(1840, 9, 1), datetime.date(1840, 5, 1), datetime.date(1840, 5, 1), datetime.date(2021, 12, 1), datetime.date(2021, 12, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 3, 21), datetime.date(2021, 6, 1), datetime.date(2021, 7, 1), datetime.date(2021, 11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHPed_cz5JsD",
        "outputId": "c3bfbf66-9bf0-4429-8094-c2cae513159a"
      },
      "source": [
        "import lexnlp.extract.en.definitions\n",
        "definitions=list(lexnlp.extract.en.definitions.get_definitions(text_data))\n",
        "if definitions:\n",
        "  print(definitions)\n",
        "else:\n",
        "  print('No definitions')\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No definitions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_etn9AJ5MJl",
        "outputId": "97cd29a7-dd4c-4f7c-e745-05fff3ee18cb"
      },
      "source": [
        "import lexnlp.extract.en.distances\n",
        "distances= list(lexnlp.extract.en.distances.get_distances(text_data))\n",
        "if distances:\n",
        "  print(distances)\n",
        "else:\n",
        "  print('No distances')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No distances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnEWzZwN5QaG",
        "outputId": "3daa545e-8dc9-46ca-8e74-d8a07cacf5b4"
      },
      "source": [
        "import lexnlp.extract.en.durations\n",
        "print(list(lexnlp.extract.en.durations.get_durations(text_data)))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('second', Decimal('20.0'), Decimal('0.0002')), ('year', Decimal('6.0'), Decimal('2190.0'))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nHeTgWW5TXP",
        "outputId": "95f2f872-813f-4a6e-a248-e58406afaa44"
      },
      "source": [
        "import lexnlp.extract.en.geoentities\n",
        "geo_config_list = []\n",
        "geo=list(lexnlp.extract.en.geoentities.get_geoentities(all_text,geo_config_list))\n",
        "if geo:\n",
        "  print(geo)\n",
        "else:\n",
        "  print('No Geo entities')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Geo entities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrscuU55VnX",
        "outputId": "07e27d7f-be12-4b34-d8c9-aa0b361f2b90"
      },
      "source": [
        "import lexnlp.extract.en.money\n",
        "print(list(lexnlp.extract.en.money.get_money(text_data)))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(Decimal('100.0'), 'USD'), (Decimal('14000.0'), 'USD'), (Decimal('14000.0'), 'USD')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOGTJj035YJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d91f35-c9fc-4de7-9522-61589e10d0bb"
      },
      "source": [
        "import lexnlp.extract.en.percents\n",
        "percents=list(lexnlp.extract.en.percents.get_percents(text_data))\n",
        "if percents:\n",
        "  print(percents)\n",
        "else:\n",
        "  print('No percents')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No percents\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__WaRJ25a61",
        "outputId": "570566cf-70f1-4c06-9e9d-bed6012aa758"
      },
      "source": [
        "import lexnlp.extract.en.pii\n",
        "print(list(lexnlp.extract.en.pii.get_pii(text_data)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tjA1zTN5dWK",
        "outputId": "ebc9aa11-d030-45f4-93c2-a1bc132452b8"
      },
      "source": [
        "import lexnlp.extract.en.ratios\n",
        "print(list(lexnlp.extract.en.ratios.get_ratios(text_data)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUCV41Yu5f_g",
        "outputId": "bc93f2bc-c651-4e1f-97f1-c5324f129f4c"
      },
      "source": [
        "import lexnlp.extract.en.regulations\n",
        "print(list(lexnlp.extract.en.regulations.get_regulations(all_text)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rizXhhkZ5iBy",
        "outputId": "3785eecc-6570-42bf-b778-46f0fb088844"
      },
      "source": [
        "import lexnlp.extract.en.trademarks\n",
        "print(list(lexnlp.extract.en.trademarks.get_trademarks(text_data)))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vylwRKEP5kxS",
        "outputId": "7f510a1e-275a-4328-9fe8-f8a553a3d631"
      },
      "source": [
        "import lexnlp.extract.en.urls\n",
        "print(list(lexnlp.extract.en.urls.get_urls(text_data)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoDeywWqBWvp",
        "outputId": "0a5c17df-aef8-4ac5-e4b6-be3af7805476"
      },
      "source": [
        "pip install pyap"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyap\n",
            "  Downloading https://files.pythonhosted.org/packages/53/b2/f0f962a5385d54cd91c153df93932b4996b793f1a2145807823d7f71328d/pyap-0.3.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pyap\n",
            "Successfully installed pyap-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPlnNLtkAuj3"
      },
      "source": [
        "import pyap\n",
        "addresses = pyap.parse(text_data, country='US')\n",
        "for address in addresses:\n",
        "  print(address)\n",
        "  print(address.as_dict())"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVJrf9x75r55",
        "outputId": "f5f0fda9-558d-444e-d7f1-d1ea8a98537b"
      },
      "source": [
        "import spacy\n",
        "spacy_nlp  = spacy.load('en_core_web_sm')\n",
        "doc = spacy_nlp(text_data.strip())\n",
        "person = set()\n",
        "for i in doc.ents:\n",
        "  entry = str(i.lemma_).lower()\n",
        "  text_sample = text_data.replace(str(i).lower(), \"\")\n",
        "  if i.label_ == \"PERSON\":\n",
        "    person.add(entry.title())\n",
        "person\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A. Quit - Claim',\n",
              " 'Allen Harrison',\n",
              " 'Austin',\n",
              " 'Austin V. Sawyer',\n",
              " 'Bibb',\n",
              " 'Booker',\n",
              " 'C. J.',\n",
              " 'Cohen',\n",
              " 'Dane',\n",
              " 'Dec Term',\n",
              " 'Dewey V. Bowman',\n",
              " 'Doughty',\n",
              " 'Edwards',\n",
              " 'Elliott V. Mayfield',\n",
              " 'Evans',\n",
              " 'Hon',\n",
              " 'Hurtell',\n",
              " 'Jacob S. Cohen',\n",
              " 'John D. Cunningham',\n",
              " 'Jones',\n",
              " 'Jun Term 1852',\n",
              " 'L. Whitlock',\n",
              " 'Lien',\n",
              " 'Lien Attach',\n",
              " 'M. J. Saffold',\n",
              " 'Mansony',\n",
              " 'Marshall',\n",
              " 'Mayfield',\n",
              " 'Mckenzie',\n",
              " 'Perkins',\n",
              " 'Poole',\n",
              " 'R. H. Smith',\n",
              " 'Sawyer',\n",
              " 'St.1821',\n",
              " 'Stewart',\n",
              " 'Stewart V. Doughty',\n",
              " 'W.',\n",
              " 'W. G. Jones',\n",
              " 'W. M. Murphy',\n",
              " 'Whipple V. Foot',\n",
              " 'Wood'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    }
  ]
}